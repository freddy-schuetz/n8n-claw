# CLAUDE.md — n8n-claw Development Guide

This file is automatically loaded by Claude Code at the start of every session.
It gives you persistent context about this project so you don't have to repeat yourself.

---

## What is n8n-claw?

A self-hosted AI agent system built on:
- **n8n** (workflow automation) — the execution engine for all agent logic
- **PostgreSQL + PostgREST** — memory, configuration, conversation history
- **Claude** (Anthropic) — the LLM powering the agent
- **Telegram** — messaging interface

The agent lives in n8n workflows. There is no custom application code — everything runs as n8n nodes connected in workflows.

---

## Repository Structure

```
n8n-claw/
├── workflows/              # n8n workflow JSON files (source of truth)
│   ├── n8n-claw-agent.json     # Main agent workflow
│   ├── mcp-builder.json        # Builds new MCP Server workflows
│   ├── mcp-client.json         # Calls tools on MCP servers (sub-workflow)
│   ├── mcp-weather-example.json # Example MCP server (Open-Meteo)
│   ├── reminder-factory.json   # Creates timed Telegram reminders
│   └── workflow-builder.json   # Builds general n8n automations (Claude Code CLI)
│
├── supabase/
│   ├── migrations/
│   │   ├── 001_schema.sql  # Full DB schema (tables, functions, roles)
│   │   └── 002_seed.sql    # Base seed data (not used directly — setup.sh handles seeding)
│   └── kong.yml            # Kong API gateway config (generated by setup.sh)
│
├── setup.sh                # Automated setup script (see below)
├── docker-compose.yml      # All services: n8n, postgres, postgrest, kong, studio, meta
├── .env.example            # Environment variable template
├── README.md               # User-facing installation guide
└── CLAUDE.md               # This file
```

---

## Database Schema

The agent reads configuration from PostgreSQL at runtime via PostgREST (`http://172.17.0.1:8000`).

| Table | Purpose | Key columns |
|---|---|---|
| `soul` | Agent personality | `key`, `content` — loaded into system prompt |
| `agents` | Tool instructions & config | `key`, `content` — loaded into system prompt |
| `user_profiles` | Per-user data | `user_id`, `display_name`, `context`, `setup_done` |
| `conversations` | Chat history | `session_id`, `role`, `content`, `created_at` |
| `memory_long` | Long-term memory | `content`, `category`, `importance`, `embedding` |
| `memory_daily` | Daily interaction log | `date`, `content`, `role` |
| `mcp_registry` | Available MCP servers | `server_name`, `path`, `mcp_url`, `tools[]`, `active` |

### Important: soul + agents are the system prompt

Every time the agent receives a message, it queries `soul` and `agents` and builds the system prompt from those rows. To change agent behavior, edit these tables — not the workflow code.

---

## Workflow Architecture

### Main Agent (`n8n-claw-agent.json`)

```
Telegram Trigger
  → Load Soul (postgres)
  → Load Agents Config (postgres)
  → Load User Profile (postgres)
  → Load Conversation History (postgres)
  → Build System Prompt (code node)
  → AI Agent (Claude Sonnet)
      ├── Memory Search (toolCode)
      ├── Memory Save (toolCode)
      ├── HTTP Tool (toolCode)
      ├── Self Modify (toolCode)
      ├── Reminder (toolWorkflow → ReminderFactory)
      ├── WorkflowBuilder (toolWorkflow → WorkflowBuilder)
      ├── MCP Builder (toolWorkflow → MCP Builder)
      └── MCP Client (toolCode)
  → Save Conversation (postgres)
  → Save Daily Log (postgres)
  → Telegram Reply
```

### MCP Builder Pattern

MCP servers are **always** built as two workflows:
1. **MCP Server workflow** — `mcpTrigger` + `toolWorkflow` node pointing to the sub-workflow
2. **Sub-workflow** — `executeWorkflowTrigger` + `code` node with actual API logic

**Why two workflows?** n8n's `toolCode` node requires `specifyInputSchema: true` for `query.*` to work, but this field is silently ignored when creating workflows via API. The `toolWorkflow` + sub-workflow pattern avoids this bug entirely — parameters arrive via `$json.param` which always works.

After building an MCP server, the user must **deactivate → reactivate** it in the n8n UI. This is a known n8n webhook registration bug with no workaround.

---

## Key Conventions

### Placeholders in workflow JSON files

All sensitive values use `{{PLACEHOLDER}}` format. `setup.sh` replaces these at deploy time:

| Placeholder | Value |
|---|---|
| `{{SUPABASE_URL}}` | `http://172.17.0.1:8000` (Docker host IP) |
| `{{SUPABASE_SERVICE_KEY}}` | JWT service role key |
| `{{N8N_URL}}` | Public n8n URL |
| `{{N8N_INTERNAL_URL}}` | `http://172.17.0.1:5678` (Docker host IP) |
| `{{N8N_API_KEY}}` | n8n API key |
| `{{TELEGRAM_CHAT_ID}}` | User's Telegram chat ID |
| `REPLACE_WITH_YOUR_CREDENTIAL_ID` | Replaced per credential type after import |

### Workflow IDs

Hardcoded workflow IDs in the agent use `REPLACE_*` placeholders:
- `REPLACE_REMINDER_FACTORY_ID`
- `REPLACE_WORKFLOW_BUILDER_ID`
- `REPLACE_MCP_BUILDER_ID`

`setup.sh` patches these after import using the actual IDs returned by the n8n API.

### Credential names (must be exact)

n8n matches credentials by name. These names are hardcoded in the workflows:
- `Anthropic API`
- `Telegram Bot`
- `Supabase Postgres`

---

## setup.sh Overview

The setup script runs in this order:

1. `apt update && apt upgrade`
2. Install Docker + psql if missing
3. Start n8n (so user can generate API key)
4. Interactive prompts: API keys, domain, personality
5. Generate Supabase JWT keys
6. Configure Kong (`supabase/kong.yml`)
7. Start all Docker services
8. Wait for n8n API to return 200
9. Apply DB schema (`001_schema.sql`)
10. Create Telegram Bot credential via n8n API
11. Try Postgres credential via n8n CLI / API fallback
12. Prepare workflows (replace placeholders in `workflows/deployed/`)
13. Import workflows in dependency order
14. Patch workflow IDs in agent
15. Activate agent workflow
16. Write personality to DB via Python (safe string escaping)
17. Print URLs, credentials, next steps

---

## Adding a New Workflow

1. Build it in n8n UI on a dev instance
2. Export as JSON (three dots → Download)
3. Replace sensitive values with `{{PLACEHOLDER}}` or `REPLACE_*` markers
4. Save to `workflows/your-workflow.json`
5. Add to `IMPORT_ORDER` in `setup.sh`
6. If the agent should use it as a tool, add a `toolWorkflow` node to `n8n-claw-agent.json`

---

## Adding a New Database Table

1. Add `CREATE TABLE` to `supabase/migrations/001_schema.sql`
2. Add `GRANT` statements so PostgREST can access it
3. Add seed data to `setup.sh` (via Python subprocess for safe escaping)

---

## Common n8n API Gotchas

- **`specifyInputSchema` is ignored on workflow CREATE** — use `toolWorkflow` + sub-workflow instead of `toolCode` for parametrized MCP tools
- **Postgres credential via API doesn't work** — must be created manually in n8n UI or via `n8n import:credentials` CLI
- **Webhook registration bug** — after activating a workflow with a webhook via API, it may not register. Fix: deactivate → reactivate in UI
- **`data` field in credentials API must be an object** — not a stringified JSON (except postgres which is the opposite — inconsistent API behavior)
- **`set -e` in setup.sh** — credential creation blocks use `set +e` to prevent aborts on API errors

---

## Local Development Tips

### Test changes without full reinstall

```bash
# Apply schema changes only
PGPASSWORD=your_pw psql -h localhost -U postgres -d postgres -f supabase/migrations/001_schema.sql

# Reimport a single workflow
N8N_KEY=your_key
curl -s -X POST "http://localhost:5678/api/v1/workflows" \
  -H "X-N8N-API-KEY: $N8N_KEY" \
  -H "Content-Type: application/json" \
  -d @workflows/deployed/mcp-builder.json
```

### Check what's in the DB

```bash
# Via psql
PGPASSWORD=your_pw psql -h localhost -U postgres -d postgres -c "SELECT key, LEFT(content,80) FROM soul;"

# Via Supabase Studio
open http://YOUR-IP:3001
```

### Tail n8n logs

```bash
docker logs -f n8n-claw
```

---

## Architecture Decisions

| Decision | Reason |
|---|---|
| Two-workflow MCP pattern | n8n API bug: `specifyInputSchema` ignored on create |
| Python for DB writes in setup.sh | Shell heredoc + psql = locale/quoting hell |
| PostgREST instead of full Supabase | Lighter, no `supabase_admin` dependencies except Studio |
| `toolWorkflow` over `toolCode` for tools | More reliable parameter passing via `$json` |
| `172.17.0.1` for internal service URLs | Docker containers can't reach `localhost` |
